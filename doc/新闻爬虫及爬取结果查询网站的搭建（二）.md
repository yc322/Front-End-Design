@[TOC](新闻爬虫及爬取结果查询网站的搭建(二）

# 概要
本节将介绍爬虫的主要流程以及具体介绍三个爬虫的代码实现。
每一个爬虫的大致步骤都是：
1、读取种子页面
2、分析出种子页面里的所有新闻链接
3、爬取所有新闻链接的内容
4、分析新闻页面内容，解析出结构化数据
5、将结构化数据存储到数据库中

在每个爬虫中，都引用了以下几个包：
其中pg.js是之前介绍的postgreSQL的连接池，iconv-lite是用来编码转换，request和cheerio在前面一章进行了介绍。
```javascript
var pgsql = require('./pg.js');
var myIconv = require('iconv-lite');
var myRequest = require('request');
var myCheerio = require('cheerio');
```
构造模仿浏览器的request是每个爬虫都包含的部分，定义来header来防止网站屏蔽，并且定义了request函数，调用该函数能够访问指定的url并且能够设置回调函数来处理得到的html页面。
```javascript
//防止网站屏蔽我们的爬虫
var headers = {
    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.65 Safari/537.36'
}

function request(url, callback) {//request module fetching url
    var options = {
        url: url,
        encoding: null,
        headers: headers,
        timeout: 10000
    }
    myRequest(options, callback)
}
```
# 雪球网
网页链接： [雪球网首页](https://xueqiu.com/)

## 分析种子页面
下图是雪球网种子界面的图，可以看出来，在雪球网热帖中，每一个新闻在div class="AnonymousHome_home__timeline__item_3vU"下面，在该种子界面，需要爬取的是每一个新闻的url以及下面的其对应的时间。
![雪球网种子界面](https://img-blog.csdnimg.cn/20200501100046233.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ljX2hvbmc=,size_16,color_FFFFFF,t_70#pic_center)
爬取种子页面，并且获取其中每一个新闻对应的链接以及时间，其对应的代码如下：
其中seedurl_news对应的页面上所有新闻，使用seedurl_news.each()对每一块新闻获取其具体url和发布时间，并且对url和时间进行了处理。
并且检查了url是否在数据库中已经存储过了。（前一节介绍过）
```javascript
var seedURL = 'https://xueqiu.com/';
request(seedURL, function (err, res, body) {
    var html = myIconv.decode(body, myEncoding);
    var $ = myCheerio.load(html, { decodeEntities: true });
    try {
        seedurl_news = $('.AnonymousHome_home__timeline__item_3vU');
    } catch (e) { console.log('url列表所处的html块识别出错：' + e) };

    seedurl_news.each(function(){
        try {
            var url = seedURL.substr(0, seedURL.lastIndexOf('/'))  + $(this).find('.AnonymousHome_a__placeholder_3RZ').attr("href");
            //时间
            time = $(this).find('.AnonymousHome_auchor_1RR').children().last().text();
            time = time.split(/\s+/)[0];
            time = '2020-' + time;
            console.log("time " + time)
        }catch (e) { 
            console.log('识别种子页面中的新闻链接出错：' + e) 
        }
        var fetch = {};
        fetch.url = url;
        fetch.source_name = source_name;
        fetch.source_encoding = myEncoding; //编码
        fetch.publish_date = time;
        
		// not try to crawl the repeat page
        var fetch_url_Sql = 'select url from fetches where url= $1';
        var fetch_url_Sql_Params = [url];
        pgsql.query(fetch_url_Sql, fetch_url_Sql_Params, function(err, result) {
            if (err) {
                console.log(err)
            } else { // a new page
                if(result.rows[0] != null) {
                    console.log(result.rows[0]);
                    console.log("URL " + url + " repeat");
                } else {
                    getDetail(fetch, url);
                }
            }
        });
    });
});
```

## 分析新闻页面
在获取了新闻详情页面后，调用getDetail函数，爬取所需要的内容。
以该页面为例：[新闻界面](https://xueqiu.com/5178802024/148437407)
爬取的信息包括：新闻标题、作者、具体内容。
新闻详情页如图：
![在这里插入图片描述](https://img-blog.csdnimg.cn/20200501164045345.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ljX2hvbmc=,size_16,color_FFFFFF,t_70#pic_center)

在获取新闻内容时，是在类名为article__bd__detail下的除了第一段的所有内容，因此对类下所有内容进行遍历，追加到content中。
具体对应的代码如下，其中fetch中存储的是在之前爬取信息的结构化存储。在文中注释部分代码是将爬取内容存到本地json文件。
```javascript
var author_format = "$('.name').text()";
var title_format = "$('.article__bd__title').text()";
function getDetail(fetch, url) {//request module fetching url
    request(url, function(err, res, body) {
        var html_news = myIconv.decode(body, myEncoding);
        var $ = myCheerio.load(html_news, { decodeEntities: true });
        console.log("转码读取成功:" + url);
        //动态执行format字符串，构建json对象准备写入文件或数据库
        fetch.title = "";
        fetch.content = "";
        fetch.crawltime = new Date();

        if (title_format == "") fetch.title = ""
        else fetch.title = eval(title_format); //标题

        if (author_format == "") fetch.author = source_name;   //作者
        else fetch.author = eval(author_format).replace("()" , "");

        //内容
        var content = ""
        for(var i = 2; i < $(".article__bd__detail").children().length; i++){
                content += $(".article__bd__detail").children().eq(i).text()
        }
        fetch.content = content
        // var filename = source_name + "_" + (new Date()).toFormat("YYYY-MM-DD") +
        //     "_" + url.substr(url.lastIndexOf('/') + 1) + ".json";
        // ////存储json
        // fs.writeFileSync(filename, JSON.stringify(fetch));

        // save the result in postgresql
        var fetchAddSql = 'INSERT INTO fetches (url, source_name, source_encoding, title, author, publish_date, content, category, read_num)' 
        + 'VALUES ($1, $2,$3,$4,$5, $6, $7,$8, $9)';
        var fetchAddSql_Params = [fetch.url, fetch.source_name, fetch.source_encoding,
            fetch.title, fetch.author, fetch.publish_date,
            fetch.content, fetch.category, fetch.read_num
        ];
        pgsql.query(fetchAddSql, fetchAddSql_Params, function(err, result) {
            if(err) {
                console.log(err);
            }
        });
    })
}
```

## 存储结果
该部分内容在数据库中的存储结果如下图：
![在这里插入图片描述](https://img-blog.csdnimg.cn/20200501165219535.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ljX2hvbmc=,size_16,color_FFFFFF,t_70#pic_center)
# 东方财富网
网页链接：[东方财富网](https://www.eastmoney.com/)
## 爬取种子页面
东方财富网的首页，和之前介绍的雪球网不同，上面广告以及其他不属于财经频道的文章链接很多，因此和之前的爬虫相比，多了一个判断链接是否符合要求。并且在种子页面，仅需要获取所有的超链接即可。
东方财富网的首页如下图:
![在这里插入图片描述](https://img-blog.csdnimg.cn/20200501170249280.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ljX2hvbmc=,size_16,color_FFFFFF,t_70#pic_center)
爬取种子页面的代码如下，主要是获取了url并且判断是否符合格式，以及判断是否重复爬取。
```javascript

request(seedURL, function(err, res, body) { //读取种子页面
    //用iconv转换编码
    var html = myIconv.decode(body, myEncoding);
    //准备用cheerio解析html
    var $ = myCheerio.load(html, { decodeEntities: true });
    var seedurl_news;
    try {
        seedurl_news = $('a');
        //console.log(seedurl_news);
    } catch (e) { console.log('url列表所处的html块识别出错：' + e) };
    seedurl_news.each(function(){
        try {
            var href = "";
            href = $(this).attr('href');
        }catch(e) {
            console.log('get the seed url err' + e);
        }
        href = String(href);
        if (href.indexOf("http://finance.eastmoney.com/a/") != 0) {
            return ;
        }

        // not try to crawl the repeat page
        var fetch_url_Sql = 'select url from fetches where url= $1';
        var fetch_url_Sql_Params = [href];
        pgsql.query(fetch_url_Sql, fetch_url_Sql_Params, function(err, result) {
            if (err) {
                console.log(err)
            } else { // a new page
                if(result.rows[0] != null) {
                    console.log(result.rows[0]);
                    console.log("URL " + href + " repeat");
                } else {
                    newsGet(href);
                }
            }
        });
    })
});
```
## 爬取新闻页面
在新闻详情页面，需要爬取新闻标题、讨论的数量、来源、内容、作者、发布日期，并且将其和url存储到结构化数据中。
以该页面为例： [网页链接](http://finance.eastmoney.com/a/202005011474210924.html)
页面标题、讨论数量、日期、来源对应的源码如下图：
![在这里插入图片描述](https://img-blog.csdnimg.cn/2020050120344782.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ljX2hvbmc=,size_16,color_FFFFFF,t_70#pic_center)

选取标题、来源、讨论人数、日期的代码如下
```javascript
var title_format = "$('.newsContent').children().eq(0).text()";

fetch.source = $('.source.data-source').text().replace('来源：', "").replace(/\s+/g, "").replace(/<\/?.+?>/g,"").replace(/[\r\n]/g, "");
fetch.read_num = $('.num.ml5').text();
fetch.title = eval(title_format);
fetch.publish_date = $('.time').text();
fetch.publish_date = fetch.publish_date.split(" ")[0];
```
正文内容所对应的源码如下图：
![在这里插入图片描述](https://img-blog.csdnimg.cn/20200501204014274.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ljX2hvbmc=,size_16,color_FFFFFF,t_70#pic_center)
爬取正文的代码如下：
```javascript
var content_format = "$('.Body').text()";
fetch.content = eval(content_format).replace('\n', "").replace(/\s+/g, "");
```
爬虫部分的完整代码如下：
包括了异常捕获、数据爬取、数据处理以及存储
```javascript
function newsGet(myURL) { //读取新闻页面
    request(myURL, function(err, res, body) { //读取新闻页面
        try {
            var html_news = myIconv.decode(body, myEncoding); //用iconv转换编码
            //准备用cheerio解析html_news
            var $ = myCheerio.load(html_news, { decodeEntities: true });
            myhtml = html_news;
        } catch (e) {    console.log('读新闻页面并转码出错：' + e);};

        console.log("转码读取成功:" + myURL);
        //动态执行format字符串，构建json对象准备写入文件或数据库
        var fetch = {};
        fetch.title = "";
        fetch.content = "";
        fetch.publish_date = (new Date()).toFormat("YYYY-MM-DD");
        //fetch.html = myhtml;
        fetch.url = myURL;
        fetch.source_name = source_name;
        fetch.source_encoding = myEncoding; //编码
        fetch.crawltime = new Date();

        if (keywords_format == "") fetch.keywords = source_name; // eval(keywords_format);  //没有关键词就用sourcename
        else fetch.keywords = eval(keywords_format);

        if (title_format == "") fetch.title = ""
        else fetch.title = eval(title_format); //标题

        if (date_format != "") fetch.publish_date = $('.time').text(); //$('.article-meta').children().eq(1).text(); //刊登日期   
        
        fetch.publish_date = fetch.publish_date.split(" ")[0];
        console.log('date: ' + fetch.publish_date);
        fetch.publish_date = fetch.publish_date.replace('年', '-')
        fetch.publish_date = fetch.publish_date.replace('月', '-')
        fetch.publish_date = fetch.publish_date.replace('日', '')
        fetch.publish_date = new Date(fetch.publish_date).toFormat("YYYY-MM-DD");

        if (author_format == "") fetch.author = source_name; //eval(author_format);  //作者
        else fetch.author = eval(author_format);
        console.log(fetch.author);

        if (content_format == "") fetch.content = "";
        else fetch.content = eval(content_format).replace('\n', "").replace(/\s+/g, ""); //内容,是否要去掉作者信息自行决定
        //console.log(fetch.content);

        if (source_format == "") fetch.source = fetch.source_name;
        else fetch.source = $('.source.data-source').text().replace('来源：', "").replace(/\s+/g, "").replace(/<\/?.+?>/g,"").replace(/[\r\n]/g, ""); //来源
        console.log(fetch.source);
        fetch.read_num = $('.num.ml5').text();

        // save the result in postgresql
        var fetchAddSql = 'INSERT INTO fetches (url, source_name, source_encoding, title, author, publish_date, content, read_num)' 
        + 'VALUES ($1, $2,$3,$4,$5, $6, $7,$8)';
        var fetchAddSql_Params = [fetch.url, fetch.source, fetch.source_encoding,
            fetch.title, fetch.author, fetch.publish_date,
            fetch.content, fetch.read_num
        ];

        pgsql.query(fetchAddSql, fetchAddSql_Params, function(err, result) {
            if(err) {
                console.log(err);
            }
        });
        
    });
}
```
## 存储结果
![在这里插入图片描述](https://img-blog.csdnimg.cn/20200501205509478.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ljX2hvbmc=,size_16,color_FFFFFF,t_70#pic_center)
# 中国财经网
网页链接：[中国财经网](http://www.chinanews.com/finance/)
## 爬取种子页面
和前面爬取东方财富网类似，在爬取种子页面时，获取其中所有超链接，与前面不同的是，这里符合条件的url形式比较复杂，因此这里采用了正则表达式对链接进行筛选。
种子页面的源码如下图所示：
![在这里插入图片描述](https://img-blog.csdnimg.cn/20200501212500179.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ljX2hvbmc=,size_16,color_FFFFFF,t_70#pic_center)

获取所有url并且进行筛选的代码如下：
这里需要爬取的是以//www.chinanews.com/cj开头并且符合正则表达式的url，再在其前面加上http:，得到需要爬取的页面的url。
```javascript
var url_reg = /\/(\d{4})\/(\d{2})-(\d{2})\/(\d{7}).shtml/;

request(seedURL, function(err, res, body) { //读取种子页面
    //用iconv转换编码
    var html = myIconv.decode(body, myEncoding);
    //console.log(html);
    //准备用cheerio解析html
    var $ = myCheerio.load(html, { decodeEntities: true });
    var seedurl_news;
    try {
        seedurl_news = $('a');
        //console.log(seedurl_news);
    } catch (e) { console.log('url列表所处的html块识别出错：' + e) };

    seedurl_news.each(function(){
        try {
            var href = "";
            href = $(this).attr('href');
        }catch(e) {
            console.log('get the seed url err' + e);
        }
        if (!url_reg.test(href)) {
            console.log(href + " not match the url_reg");
            return;
        }
        href = String(href);
        if (href.indexOf("//www.chinanews.com/cj") != 0) {
            // console.log(href + " not match the right url");
            return ;
        }
        href = 'http:' + href;
        console.log("crawler " + href);

        // not try to crawl the repeat page
        var fetch_url_Sql = 'select url from fetches where url= $1';
        var fetch_url_Sql_Params = [href];
        pgsql.query(fetch_url_Sql, fetch_url_Sql_Params, function(err, result) {
            if (err) {
                console.log(err)
            } else { // a new page
                if(result.rows[0] != null) {
                    console.log(result.rows[0]);
                    console.log("URL " + href + " repeat");
                } else {
                    newsGet(href);
                }
            }
        });
    })
});
```
## 爬取新闻页面
在新闻详情页面，需要爬取新闻标题、来源、内容、作者、发布日期，并且将其和url存储到结构化数据中。
以该页面为例： [网页链接](http://www.chinanews.com/cj/2020/04-30/9172513.shtml)

标题、日期、来源所对应的源代码如下：
![在这里插入图片描述](https://img-blog.csdnimg.cn/20200501222650337.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ljX2hvbmc=,size_16,color_FFFFFF,t_70#pic_center)

爬取这些信息的代码如下：
```javascript
var title_format = "$('.content > h1').text()";
var date_format = "$('#pubtime_baidu').text()";
var source_format = "$('.left-t').text()";
fetch.title = eval(title_format); //标题
fetch.publish_date = eval(date_format); //日期
fetch.publish_date = fetch.publish_date.split(" ")[0];
fetch.source = eval(source_format).split('：')[1]; //来源
fetch.source = fetch.source.replace('参与互动', '');
```
具体页面内容的源代码如下图：
![在这里插入图片描述](https://img-blog.csdnimg.cn/20200501222849421.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ljX2hvbmc=,size_16,color_FFFFFF,t_70#pic_center)
爬取文章内容的代码如下：
```javascript
var content_format = "$('.left_zw').text()";
fetch.content = eval(content_format).replace('\n', "").replace(" ", "");
```

完整的爬取文章页面的代码如下：
```javascript
function newsGet(myURL) { //读取新闻页面
    request(myURL, function(err, res, body) { //读取新闻页面
        try {
            var html_news = myIconv.decode(body, myEncoding); //用iconv转换编码
            //准备用cheerio解析html_news
            var $ = myCheerio.load(html_news, { decodeEntities: true });
            myhtml = html_news;
        } catch (e) {    console.log('读新闻页面并转码出错：' + e);};

        console.log("转码读取成功:" + myURL);
        //动态执行format字符串，构建json对象准备写入文件或数据库
        var fetch = {};
        fetch.title = "";
        fetch.content = "";
        fetch.publish_date = (new Date()).toFormat("YYYY-MM-DD");
        //fetch.html = myhtml;
        fetch.url = myURL;
        fetch.source_name = source_name;
        fetch.source_encoding = myEncoding; //编码
        fetch.crawltime = new Date();

        if (title_format == "") fetch.title = ""
        else fetch.title = eval(title_format); //标题

        if (date_format != "") fetch.publish_date = eval(date_format); //$('.article-meta').children().eq(1).text(); //刊登日期   
        console.log(fetch.publish_date);
        fetch.publish_date = fetch.publish_date.split(" ")[0];
        console.log('date: ' + fetch.publish_date);
        fetch.publish_date = fetch.publish_date.replace('年', '-')
        fetch.publish_date = fetch.publish_date.replace('月', '-')
        fetch.publish_date = fetch.publish_date.replace('日', '')
        fetch.publish_date = new Date(fetch.publish_date).toFormat("YYYY-MM-DD");

        if (author_format == "") fetch.author = source_name; //eval(author_format);  //作者
        else fetch.author = eval(author_format).replace('作者：','');
        console.log("作者 " + fetch.author);

        if (content_format == "") fetch.content = "";
        else fetch.content = eval(content_format).replace('\n', "").replace(" ", ""); //内容,是否要去掉作者信息自行决定

        console.log("get the source");
        if (source_format == "") fetch.source = fetch.source_name;
        else fetch.source = eval(source_format).split('：')[1]; //来源
        fetch.source = fetch.source.replace('参与互动', '');
        console.log(fetch.source);
        
        // save the result in postgresql
        var fetchAddSql = 'INSERT INTO fetches (url, source_name, source_encoding, title, author, publish_date, content)' 
        + 'VALUES ($1, $2,$3,$4,$5, $6, $7)';
        var fetchAddSql_Params = [fetch.url, fetch.source, fetch.source_encoding,
            fetch.title, fetch.author, fetch.publish_date, fetch.content
        ];

        pgsql.query(fetchAddSql, fetchAddSql_Params, function(err, result) {
            if(err) {
                console.log(err);
            }
        });
        
    });
}
```

## 存储结果
爬虫的结果在pgSQL中的部分结果如下图所示：
![在这里插入图片描述](https://img-blog.csdnimg.cn/20200501223555421.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ljX2hvbmc=,size_16,color_FFFFFF,t_70#pic_center)


